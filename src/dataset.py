# prepare dataset 
from bitty import Tokenizer
from bitty.chunking import Tokenizer
class Dataset:
    def __init__(self, vocab_path):
        pass

    def data_to_tokens(self, ):
        # encoder path          
        pass


if __name__ == '__main__':
    vocab_path = ''

    Tokenizer()

    # load the vocab path here 

