The scope is to make a model from scratch and only using torch library  

Here I am using tokenizer from bitty-ai that we created earlier 

1. So first tokenize that dataset create a nice .bin file for it 
* create base layers for the same 
2. Define the architecture file in the src/ 
3. Then use it to train a model on that dataset with multiple configurable parameters
4. Then use that to evaluate on validation dataset 
5. Check memory usage and research on this, create a nice detailed video over it .. 

